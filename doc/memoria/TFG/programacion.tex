%chapter introduce un nuevo capítulo
\chapter{Programación}\label{chapterprogramacion}

En este capítulo se presenta el desarrollo de todo el software que ha sido requerido preparar para la puesta en marcha del robot. El objetivo final del apartado es la programación de la librería \textit{raider.h}, que centraliza todas las funcionalidades de RAIDER.

\section{Configuración de la BeagleBone Black}

El controlador principal, la BeagleBone Black, trae de fábrica una instalación de una distribución Ångström basada en Linux. El sistema operativo incluye: entorno gráfico, escritorio, OpenCV 2.2 y otros programas como navegadores o reproductores de archivos multimedia. Esto se debe a que la BeagleBone Black no es una placa que de fábrica esté pensada para su uso en robots, sino que constituye un ordenador completo que puede adquirir la función de centro multimedia, equipo de ofimática o incluso servidor de una red.

\subsection{Sistema operativo}

La distribución Ångström no es una de las más populares entre los sistemas operativos basados en Linux, no cuenta con una comunidad de usuarios tan amplia como Debian o Fedora. Por ello, las actualizaciones no suelen ser muy frecuentes y, en muchos casos, el sistema presenta errores de funcionamiento a la hora de realizar tareas básicas, como la instalación de nuevo software.

\medskip Por esta razones se ha decidido instalar un nuevo sistema operativo. Se pretende conseguir una distribución de Linux que solo tenga lo mínimo necesario que requiere el robot para su funcionamiento. Con este objetivo, se instala en la BeagleBone Black una distribución Debian.

\subsection{Instalación de librerías}

Para la realización del proyecto, se ha requerido instalar Git, CMake, Video4Linux2 y las librerías de OpenCV 2.4.8 y ZBar 0.1.

\medskip Antes de comenzar con la instalación de software, es recomendable realizar una actualización del sistema ejecutando los siguientes comandos:

\begin{verbatim}
sudo apt-get update
sudo apt-get upgrade
\end{verbatim}

\bigskip  Lo primero que instalaremos será Git, ya que lo necesitaremos para instalar algunas librarías posteriormente. Git se instala ejecutando el siguiente comando: 
\begin{verbatim}
sudo apt-get install git-core
\end{verbatim}

\bigskip Para instalar CMake lo haremos de la siguiente forma:

\begin{verbatim}
sudo apt-get install cmake
sudo apt-get install cmake-curses-gui
\end{verbatim}

\bigskip Para el control y configuración de la webcam se necesitará el driver Video4Linux. Se instalará como se muestra a continuación:

\begin{verbatim}
sudo apt-get install v4l-utils
\end{verbatim}


\bigskip  Una vez hecho esto, se pasará a instalar las librerías que se utilizarán en el código del robot. La forma mas sencilla de instalar Zbar será hacerlo desde los repositorios de Debian. De este modo, ejecutaremos los siguientes comandos:
\begin{verbatim}
sudo apt-get install libzbar0
sudo apt-get install libzbar-dev
\end{verbatim}

\bigskip  Por último, instalaremos OpenCV. Se comenzará por descargar todas las librarías que requiere OpenCV. Se instalarán una a una de la siguiente forma:
\begin{verbatim}
sudo apt-get install build-essential 
sudo apt-get install libgtk2.0-dev 
sudo apt-get install pkg-config 
sudo apt-get install python-dev 
sudo apt-get install python-numpy 
sudo apt-get install libavcodec-dev 
sudo apt-get install libavformat-dev 
sudo apt-get install libswscale-dev
\end{verbatim}

Hecho esto, se procederá a descargar la última versión estable del código, que en este momento es la 2.4.9.

\begin{verbatim}
wget http://downloads.sourceforge.net/project/opencvlibrary/opencv-unix/2.4.9/opencv-2.4.9.zip
\end{verbatim}

\bigskip Y posteriormente se instalará de este modo:

\begin{verbatim}
unzip opencv-2.4.9.zip
cd opencv-2.4.9
mkdir build
cd build
cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local ..
make
sudo make install
\end{verbatim}

\subsection{Configuración de la cámara}

A continuación se configurará la webcam en la beaglebone. Para esto se conectará por USB la Microsoft Lifecam a la BeagleBone Black tal y como puede observarse en la figura \ref{robotbbbcam}. A partir de aquí, se iniciará sesión en la BeagleBone Black y se procederá a configurar la cámara.

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{figuras/robotbbbcam}   
\caption{Conexión de la cámara a la BeagleBone Black}
\label{robotbbbcam}
\end{figure}
\FloatBarrier

\medskip Lo primero que se hará será comprobar que la cámara se ha reconocido correctamente. Para ello ejecutaremos el comando:

\begin{verbatim}
lsusb
\end{verbatim}

\bigskip Y deberá proporcionarnos una salida parecida a la que puede observarse en la figura \ref{lsusbbbb}. La salida indica que la webcam está conectada en el bus 001

\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{figuras/lsusbbbb}   
\caption{Salida del comando lsusb}
\label{lsusbbbb}
\end{figure}
\FloatBarrier

\medskip Para cerciorarno de que la cámara se ha reconocido correctamente podemos buscarla en el directorio /dev. En la imagen \ref{lsdev} se observa el archivo /dev/video0, que está vinculado a la webcam.

\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{figuras/lsdev}   
\caption{Comprobación de conexión para la webcam}
\label{lsdev}
\end{figure}
\FloatBarrier

A continuación nos ayudaremos de las utilidades de Video4Linux (una interfaz para la programación de aplicaciones con captura de imágenes para Linux) para la webcam. OpenCV se apoya en Video4Linux, por tanto, lo primero que se hará será comprobar que la cámara es compatible con Video4Linux. Para ello, se ejecutará el siguiente comando:

\begin{verbatim}
v4l2-ctl --list-devices
\end{verbatim}

\bigskip Tras ejecutarlo se deberá observar una salida similar a la de la figura \ref{v4llist}

\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{figuras/v4llist}   
\caption{Comprobación de compatibilidad para la webcam}
\label{v4llist}
\end{figure}
\FloatBarrier

Ésto nos confirma que la cámara funciona correctamente. Para proseguir con la configuración vamos a ejecutar el comando siguiente:

\begin{verbatim}
v4l2-ctl --all
\end{verbatim}

\bigskip  En la figura \ref{v4lall} podemos observar la salida del comando. En ella se pueden observar diferentes parámetros como el formato de video, la resolución o los fotogramas por segundo.

\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{figuras/v4lall}   
\caption{Parámetros leídos de la cámara}
\label{v4lall}
\end{figure}
\FloatBarrier

\medskip Por último, se bajará la resolución de la cámara a un valor que nos permita tratar las imágenes con mayor rapidez cuando se programen algoritmos de visión con OpenCV desde la BeagleBone Black. Se ha elegido una resolución de 320x240, mas adelante se ajustará este valor empíricamente en función del rendimiento del robot. Para ello ejecutamos este comando de configuración:

\begin{verbatim}
v4l2-ctl --set-fmt-video=width=320,heigth=240
\end{verbatim}

\bigskip  Tras estos pasos la cámara ya está preparada y lista para usarse.

%vdeo capture aplication progamin interface for linux

\subsection{Configuración de pines}

Para finalizar esta sección, se muestra el desarrollo de un script para configurar los pines del controlador.

\medskip La Beaglebone Black posee 92 pines configurables de entrada y salida. Entre ellos, 7 pueden funcionar como entradas analógicas y 5 parejas de pines están preparadas como puertos serie, tal y como indica la figura \ref{bbbserial}.

\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{figuras/bbbserial}   
\caption{Puertos serie en una BeagleBone Black}
\label{bbbserial}
\end{figure}
\FloatBarrier

Para configurar los pines de la placa se utilizarán overlays (capas). Un overlay es un archivo que indica al sistema operativo cómo debe configurarse un pin. La BeagleBone Black se configura mediante Device Tree Overlays, un mecanismo de descripción del hardware que forma parte de un sistema. Para configurar las entradas analógicas necesarias para los sensores infrarrojos, y el puerto serie que comunicará la placa con el controlador de locomoción; se utilizarán los archivos \textit{.dtbo} que pueden encontrarse en \textit{/lib/firmware} y aparecen en la figura \ref{libfirmware}.


\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{figuras/libfirmware}   
\caption{Algunas capas de Device Tree Overlays}
\label{libfirmware}
\end{figure}
\FloatBarrier

\medskip En concreto se utilizarán dos capas, la que activará el puerto serie número 2: \textit{ttyO2\_armhf.com} y esta otra que nos permitirá activar las entradas analógicas: \textit{cape-bone-iio}. Se habilitarán como se muestra en la figura \ref{overlays}.

\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{figuras/overlays}   
\caption{Habilitación de capas}
\label{overlays}
\end{figure}
\FloatBarrier

\medskip Puede realizarse una comprobación simple de que los pines se han configurado correctamente realizando una lectura analógica. Para ello, se leerá el archivo \textit{/sys/bus/platform/drivers/bone-iio-helper/helper.15/AIN4}. En la figura \ref{catain4} se ha realizado una lectura del pin 4, el valor de 570 indica que se está realizando una lectura de $570mV$.

\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{figuras/catain}   
\caption{Lectura analógica del pin 4}
\label{catain4}
\end{figure}

Para realizar estas medidas desde el programa principal escrito en C++, se ha programado la librería \textit{bone.h}, que simplifica el uso de estos pines.

\section{Sistema de locomoción TODO}

Antes de comenzar con esta sección, es importante señalar algunos detalles importantes. Si bien es cierto, el control del robot girará en torno a un algoritmo de visión, su funcionamiento de apoyará en un control de locomoción robusto que permita al robot realizar desplazamientos seguros sobre el terreno. Por tanto, dado que se trata de un robot bípedo, la programación de movimientos no es un tema trivial como lo podría ser en un robot con ruedas.

Para conseguir que Raider pueda moverse con soltura se han seguido varios pasos, cada cual de un nivel superior al anterior.

\subsection{Movimiento del servo PWM}


El control del servo PWM de Raider, situado en su cabeza, se realiza con la biblioteca Servo.h orginalmente desarrolladas para Arduino y que posteriormente ha sido portada para su utilización en OpenCM. Dado el cometido de este servo, no será necesario realizar un control de su velocidad, por lo que un simple control de su posición será suficiente.

La biblioteca Servo.h nos permite controlar el movimiento de un servo a partir de un valor de posición, y se encarga de producir la señal PWM correspondiente. Aunque los métodos utilizados pueden encontrarse en la documentación de Arduino ( TODO ), a continuación introduzco una breve explicación de los que han sido utilizados en este proyecto:

\subsubsection{Servo::attach(uint8 pin)}

Con esta función configuramos un pin de la OpenCM para que actúe como emisora de señales PWM. A partir de esta inicialización ya puede moverse el servo.

\subsubsection{Servo::writeMicroseconds(uint16 pulseWidth)}

Para mover el servo se utiliza la función writeMicroseconds, cuyo parámetro define la amplitud  del pulso de la onda PWM. Si bien es cierto, existe otra función paralela llamada write(int angle) que directamente utiliza como parámetro la posición en grados, se ha utilizado writeMicroseconds por su mayor precisión. Acepta valores de entre 1000 y 2000 microsegundos, pero para mantener un formato constante con el resto de articulaciones, se ha realizado una conversión matemática a un rango de 0 a 1023.

\subsection{Movimiento de los actuadores Dynamixel}

Para comunicarse con los actuadores Dynamixel (de los que hablamos en TODO ) debemos utilizar su protocolo particular. Los servos son controlados mediante el envio de paquetes de datos binarios. Existen dos tipos de paquetes en el protocolo: Los paquetes de instrucciones, que son los que envia el controlador a los servos; y los paquetes de estado, que son los los servos envían al controlador.

\medskip 
Cada servo tiene una ID, o dicho de otra forma, un número de identidad propio e irrepetible que identifica a un servo particular dentro del bus. La comunicación en el bus se realiza mediante el intercambio de paquetes de instrucciones y estados con una ID concreta.
Por esta razón, en un mismo bus no deben existir servos con la misma ID, ya que provocarán colisiones entre los paquetes e impedirán el correcto funcionamiento del sistema. Sin embargo, estas ID son fácilmente reprogramables y pueden modificarse realizando una escritura sobre el registro 3 (0X03).

\medskip 
El protocolo de comunicación utilizado es una comunicación serie asíncrona de 8 bits, con 1 bit de Stop y sin paridad. La conexión, de tipo Half Duplex, no permite la transmision y recepción de paquetes de forma simultanea. Esto la convierte en una conexión bastante típica en los sistema que utilizan un solo bus de comunicación. Como en el mismo bus existe mas de un dispositivo, todos deben permanecer en modo de escucha salvo el que esté transmitiendo en ese instante. El controlador principal, la placa OpenCM 9.04, asigna la dirección del bus en modo escucha, y solo cambia la dirección del bus a modo de envio mientras manda un paquete. Los Dynamixel AX-12A poseen una tabla de registros sobre la cual podemos modificar varios parámetros referente a su estado y su funcionamiento. La tabla de registros puede consultarse en el manual\cite{robotis2010dynamixel}.

\medskip 
Para realizar una rotación simple en un servomotor, sería suficiente con escribir en el registro 32 (Goal Position) un valor comprendido entre 0 y 1023, y el servo se situará inmediatamente en esa posición. Sin embargo, existen otros parámetros interesantes en el mapa de registros que conviene controlar, como la posición instantanea, la velocidad de giro, el consumo eléctrico o incluso la temperatura del dispositivo.

\medskip 
Para mover los 19 AX-12A de Raider se utilizan los parámetros de posición objetivo (Goal Position) y velocidad de giro (Moving Speed) de forma combinada. Dado que está programación se ha realizado desde la OpenCM 9.04 se ha utilizado la biblioteca Dynamixel.h, que funciona como una macro para leer y escribir en los registros de forma sencilla y eficiente. Dentro de la biblioteca utilizaremos la función writeWord con la siguiente sintaxis:

% TODO arreglar codigos

\begin{verbatim}
Dxl.writeWord(
	Dynamixel_Motor_Number,	
	Address_Number,
	Address_Data
);
\end{verbatim}

A modo de ejemplo, para asignar una velocidad de $3.5rad/s$ al servo con la ID 5, primero calcularíamos el valor correspondiente para una resolución de 10 bits. Según el manual de los servos Dynamixel ( TODO citar) AX-12A, la velocidad máxima de estos servomotores es de $114rpm$. Por tanto, se realizaría la siguiente conversión:

\[ 3.5 \cdot \frac{rad}{s} \cdot \frac{60 s}{2 \pi rad} \cdot rpm \cdot \frac{1024}{114 rpm}= 300.216 \simeq 300 \]

\medskip
Dentro del código, utilizaremos la función writeWord para asignar este valor en el registro 32 (Moving Speed):

% TODO arreglar codigos
\begin{verbatim}
Dxl.writeWord(5,32,300);
\end{verbatim} 

Seguidamente, asignaríamos al servo una posición final siguiendo el criterio de la figura \ref{goalposition}

\begin{figure}[h]
\centering
\includegraphics[width=0.55\textwidth]{figuras/goalposition}   
\caption{Amplitud de giro de un AX-12A}
\label{goalposition}
\end{figure}

Continuando con el ejemplo, calcularemos el valor que debemos darle al registro para mover el servo a una posición de $120º$, teniendo en cuenta que las especificaciones nos indican una amplitud de giro total de 300º reales con una resolución de 10 bits. De esta forma, haríamos la siguiente conversión:

\[ 120º \cdot \frac{1024}{300º}= 409.6 \simeq 410 \]

\medskip
En nuestro programa escribiríamos en el registro 30 (Goal Position) de la siguiente forma:

% TODO arreglar codigos
\begin{verbatim}
Dxl.writeWord(5,30,410);
\end{verbatim} 

Como resumen, con estos pasos hemos conseguido mover el servo con la ID 5 (Que corresponde al codo del brazo izquierdo de Raider), a una posición de $120º$ con una velocidad de $3.5 rad/s$

\subsection{Movimiento sincronizado de las articulaciones}

En el apartado anterior se ha mostrado cómo se realiza el movimiento de un servo, sin embargo, para mover el cuerpo del robot necesitaremos mover todos al mismo tiempo de una forma sincronizada. Si en el apartado anterior utilizabamos la posición objetivo y la velocidad de movimiento como parámetros, en este punto, por comodidad a la hora de programar, utilizaremos como parámetros la posición objetivo de los 20 servos, su posición actual y el tiempo total durante el que se realizará su movimiento entre ambos puntos.

\medskip
Este es quizás uno de los apartados mas críticos a la hora de diseñar las funciones que moverán el robot. Se pretende programar una biblioteca que permita mover 20 servos simultaneamente, con velocidades diferentes condicionadas por un tiempo de ejecución común. De esta forma, los servos cuya posición objetivo sea lejana a su posición actual se moverán con una velocidad mayor que la de los servos cuya posición objetivo sea cercana a su posición actual.

\medskip
Las funciones pueden encontrarse en la biblioteca \textit{motion.h}.

\subsubsection{class Robot} 

La clase Robot abarca todas las funciones relativas al movimiento de Raider (aunque por el momento en esta sección solo se presenta algunas de ellas), y abstrae su controlador principal, la BeagleBone Black de la parte de locomoción. Dentro de la clase, encontramos tres variables miembros importantes:

\begin{itemize}
\item \textbf{int currentPosition[20]}.

currentPosition es un array de 20 posiciones destinado a almacenar los valores de las posición actual de las 20 articulaciones del robot con valores comprendidos entre 0 y 1023. El primer valor es el servo AX-12A, el segundo es el servo PWM de la cabeza y a partir de ese punto están el resto de AX-12A ordenados según su ID, del número 1 al 18.

\item \textbf{int targetPostion[20]}.

targetPosition sigue la misma estructura de currentPosition, con la diferencia de que en este caso los valores guardados en el array corresponderán con la posición objetivo o posición final de las articulaciones.

\item \textbf{int TRIM[20]}.

Por último, TRIM es un array de trims. Un trims es una variable de ajuste para calibrar la posición de los servos. Tanto los servos Dynamixel como los servos PWM suelen tener un pequeño error en su posición cero. Los trimmers constituyen un offset aplicado individualmente a cada servo en absolutamente todos los movimientos que se realizarán durante el programa. Las holguras y otros factores pueden provocar el desajuste de esto valores, por lo que es necesario volver a calibrarlo cada cierto tiempo. Una mala calibración de los trims puede radicar en problemas de asimetrías en movimientos, y por tanto, resultados inesperados.

\end{itemize}

\subsubsection{Robot::Robot()}

El constructor de la clase Robot tiene como función la apertura del bus de control para los servos AX-12A, la configuración del servo PWM y la asignación de trims en el array de trims.
 


\subsubsection{void Robot::setTargetPosition(int,int,... int)}

setTargetPosition accede directamente al miembro privado targetPosition[20] para asignarle nuevos valores.

\subsubsection{void Robot::setTargetOffset(int,int,... int)}

setTargetOffset varía los valores del miembro privado targetPosition[20] para sumarles un valor. La función permite variar una posición con un giro determinado sin necesidad de conocer la posición actual de la articulación.


\subsubsection{void Robot::updateCurrentPosition()}

Esta función tiene un funcionamiento sencillo, se ocupa de volcar los datos de la posición objetivo en la posición actual. Es la forma que tiene el robot de actualizar su posición actual tras un movimiento. 

\subsubsection{void Robot::move(float)} 

La función move es la mas importante de todas, ya que es la función que se encarga de mover las articulaciones. A esta función se le pasa un valor de tiempo expresado en segundos, y tal y como se comentó al principio de este apartado, será el tiempo en el que los servos pasarán de la posición actual (currentPosition[20]) a la posición final (targetPosition[20]).

\medskip
Para ello, la función calcula la amplitud del movimiento y asigna una velocidad independiente para ese servo. Gracias a esto, todos los servos empiezan y terminan de moverse al mismo tiempo y permiten un control mas sencillo de las inercias entre movimientos consecutivos.

\subsection{Funciones de movimientos combinados TODo } 

Llegado este punto se ha abordado como mover un servo y como mover los 20 servos de forma coordinada. En este apartado se presentan algunas funciones intermedias entre lo comentado y movimientos de alto nivel, como puede ser el desplazamiento bípedo.

\medskip
Para facilitar la programación de movimientos mas complejos se han programado una seríe de utilidades que permiten mover los servos en pequeños grupos que desempeñan una funcion común. Estas funciones modifican los valores del array de posiciones finales, targetPosition[20], lo que quiere decir que para efectuar el movimiento será necesario realizar una llamada a la funcion move(float). Por tanto, es posible la utilización de varias funciones en un mismo movimiento, dando la posibilidad de sumar sus modificaciones y superponer su utilidades. 

\subsubsection{void movHead(int)}

movHead es una función que permite mover el servo PWM de la cabeza del robot. Sirve para mover la cámara independientemente de la posición instantanea del robot.


% Dibujos y otras movidas
\subsubsection{void movVertical(int,int) TODO}
Meter fotos del robot con una pierna levantada
\subsubsection{void movLateral(int,int) TODO}
\subsubsection{void movFrontal(int,int) TODO}

\subsection{Creación de movimientos completos}

Encontrándonos en este punto, la programación de desplazamientos, giros y otros movimientos complejos, se ha realizado mediante la combinación de las funciones anteriormente descritas. A cada movimiento se le asignará un valor hexadecimal en forma de caracter, de forma que los caracteres comunicados a la OpenCM sirvan como identificador de el movimiento que el controlador de visión está ordenando.

\medskip Se ha creado la función void controller(char), dentro de la clase Robot, con el objetivo de indexar todos los movimientos que realizará Raider. En el cuadro \ref{movimientos} se presenta una tabla con los movimientos programados y su comando asignado.

\begin{table}[H]
\centering
\begin{tabular}{p{1.5cm} p{2cm} p{8cm}}
\hline
Comando & Función & Descripción \\
\hline \hline
\centering W & walk(3) & Caminar 3 pasos cortos\\ \hline
\centering A & turnL() & Rotación a la izquierda  \\ \hline
\centering D & turnR() & Rotación a la derecha  \\ \hline
\centering S & run(3) & Caminar 3 pasos largos y rápidos  \\ \hline
\centering Q & stepL() & Paso lateral a la izquierda  \\ \hline
\centering E & stepR() & Paso lateral a la derecha  \\ \hline
\centering K & kick() & Patada (para golpear una pelota)  \\ \hline
\centering Y & yes() & Movimiento intermitente de la cabeza  \\ \hline
\centering G & getUp() & Levantamiento desde una caída frontal  \\ \hline
\centering R & roll() & Rodar, se utiliza cuando el robot cae de espaldas  \\ \hline
\centering H & hello() & Saludo  \\ \hline
\centering q & miniTurnL() & Giro leve hacia la izquierda  \\ \hline
\centering e & miniTurnR() & Giro leve hacia la derecha  \\ \hline
\centering Z & punchL() & Puñetazo con el brazo izquierdo  \\ \hline
\centering B & punchR() & Puñetazo con el brazo derecho  \\ \hline
\centering C & crab() & Ataque de sumo con dos brazos  \\ \hline
\centering V & miniPunchR() & Puñetazo leve derecho  \\ \hline
\centering X & miniPunchL() & Puñetazo leve izquierdo  \\ \hline
\centering w & defense() & Posición defensiva  \\ \hline
\centering a & lookL() & Mirar hacia la izquierda  \\ \hline
\centering d & lookR() & Mirar hacia la derecha  \\ \hline
\centering L & look() & Mirar de frente  \\ \hline
\centering l & lookUp() & Mirar hacia arriba  \\ \hline
\centering f & endLookUp() & Volver a la posición de reposo tras lookUp()  \\ \hline


\end{tabular}
\caption{Movimientos programados}
\label{movimientos}
\end{table}

\section{Comunicación serie}

En la sección anterior hemos completado la programación de movimientos sobre la placa OpenCM, sin embargo, el control principal del robot se realiza desde la BeagleBone. En este apartado se comunicará la BeagleBone con la OpenCM de forma que adopten una configuración de maestro y esclavo. La estrategia consistirá en el envío de comandos hexadecimales desde la BeagleBone a la OpenCM. Cada comando servirá de identificador para un movimiento completo. Los comandos serán los descritos en el cuadro \ref{movimientos}.


\subsection{Comunicación serie en OpenCM}

La OpenCM posee 3 puertos serie, de los cuales uno de ellos está reservado para el control del bus Dynamixel. En el esquema de la figura \ref{serialcm} se presenta la configuración de puertos serie de la OpenCM.

\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{figuras/serialcm}   
\caption{Esquema de puertos serie en una OpenCM 9.04}
\label{serialcm}
\end{figure}
\FloatBarrier

Para la programación de la comunicación serie en la placa OpenCM se ha utilizado la biblioteca HardwareSerial.h, contenida en CM9 IDE. A continuación se listan las funciones que se han utilizado junto a una breve explicación de su funcionamiento.

\subsubsection{void HardwareSerial::begin(unsigned int baud)}

Esta función habilita los pines como puerto serie. Como parámetro se le pasará la velocidad en baudios, que deberá coincidir con la del controlador maestro. En este caso, se ha configurado el puerto 3 con una velocidad de 9600 baudios

\subsubsection{unsigned int HardwareSerial::available()}

El objetivo de esta función es consultar si existe algún mensaje en el buffer de lectura. En caso afirmativo, podremos proceder a leer el mensaje.

\subsubsection{unsigned char HardwareSerial::read()}

La lectura de mensajes nos devolverá un valor hexadecimal. En nuestro caso, será el emitido por la BeagleBone Black y corresponderá a la ejecución de un movimiento.

\subsubsection{void HardwareSerial::flush()}

Con esta función vaciaremos el buffer de entrada. Se ejecutará cada vez que leamos un comando.
 
\subsection{Comunicación serie en BeagleBone}

Para poner en amrcha la comunicación serie en la BeagleBone se ha utilizado como base la librería open-source Serialib \cite{webserialib}. Esta librería nos permite administrar un puerto serie, y está preparada para funcionar tanto en Windows como en Linux. 

\medskip Se han realizado algunas modificaciones leves para ajustar su funcionamiento al requerido. Los métodos que se han utilizado se detallan a continuación.

\subsubsection{open TODO nombre }

Esta función abrirá el puerto serie. En el primer parámetro se le pasará la cadena ``/dev/ttyO2", es decir, la dirección de nuestro puerto serie. Como segundo parámetro se le pasará la velocidad del puerto, que coincidiendo con la de la OpenCM será de 9600 baudios.

\subsubsection{writechar TODO nombre }

Para mandar los comandos utilizaremos esta función. Ya que el objeto de la clase conserva las carácterísticas del puerto serie, solo será necesario pasarle el valor hexadecimal que queramos transmitir al controlador de locomoción.

\subsection{Comunicación con módulo Bluetooth}

Adicionalmente, se ha incluido la posibilidad de utilizar un control auxiliar por Bluetooth desde un dispositivo externo. Para ello se ha conectado un modulo Bluetooth directamente a la OpenCM. La función de esta otra vía de control no es otra que la realización de pruebas experimentales controladas, ya que nos permite modificar el comportamiento del robot en los momentos en los que sea necesario. Por supuesto, de cara a su funcionamiento autónomo, el módulo Bluetooth se inutilizará. Sin embargo, será necesario dejar preparada su conexión y programación.

Se ha utilizado un módulo Bluetooth hc05 conectado al puerto 3 del controlador de locomoción. Con esto, podremos mandar mensajes desde un teléfono móvil, un ordenador portátil o cualquier otro dispositivo que soporte conexión Bluetooth. Para utilizar el control del robot por Bluetooth se sustituirá el puerto de lectura de la OpenCM reservado al controlador de visión (el puerto 2) por el puerto 3. En la imágen \ref{raiderblue} puede apreciarse cómo se controla a RAIDER desde un teléfono móvil.

\begin{figure}[h]
\centering
\includegraphics[width=0.75\textwidth]{figuras/raiderblue}   
\caption{Teleoperación de RAIDER con módulo Bluetooth}
\label{raiderblue}
\end{figure}
\FloatBarrier

\section{Programación de sensores} 

En esta sección se detallará la programación que se ha aplicado a los diferentes sensores que se han montado en RAIDER.

\subsection{Infrarrojos}

Para controlar los sensores infrarrojos se ha desarrollado un algoritmo de detección, implementado en la librería \textit{raider.h}. Dado el carácter de este sensor, se ha realizado una programación para detectar objetos en función de dos parámetros de distancia crítica. Como puede observarse en la figura \ref{esquemarango} con estos dos parámetros (representados por barras verticales) se han definido tres zonas.

\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{figuras/esquemarango}   
\caption{Rangos de detección para un sensor Sharp}
\label{esquemarango}
\end{figure}
\FloatBarrier

El rango de datos que podemos extraer de la entrada analógica va de 0 a 1800mV. Teniendo esto en cuenta, se han definido experimentalmente \textit{INFRARED\_LOW} en 300mV, e \textit{INFRARED\_HIGH} en 1000mV. Estos valores corresponden aproximadamente a 12cm y 40cm respectivamente. Se han desarrollado dos funciones paralelas para medir los sensores infrarrojos izquierdo y derecho de Raider: \textit{getLeftIR()} y \textit{getRightIR()}. Estas funciones devolverán un valor identificativo de la zona en la que se encuentra el obstáculo.

\subsection{IMU TODO}

La programación del sensor inercial pasa por dos fases: La extracción de datos del sensor y el procesamiento de los mismos para obtener información útil.

\medskip El MPU9150 utiliza el protocolo I2C para comunicarse con el controlador. Ofrece medidas de giroscopio, acelerómetro y magnetómetro. En este proyecto se ha utilizado solamente el acelerómetro para detectar caídas. No obstante, se han programado funciones para la lectura de todos los parámetros con el objetivo de utilizarlos en futuros desarrollos. Para utilizar el bus I2C de la BeagleBone Black se ha desarrollado la librería \textit{i2c.h}, que funciona como interfaz de la librería nativa \textit{i2c-dev}. Para programar este sensor habrá que apoyarse en el mapa de registros \cite{registermapimu}.

\medskip El primer paso para utilizar este sensor es desactivar el modo de hibernación. Esto se consigue poniendo a 0 el registro 6B. Una vez hecho esto ya pueden leerse de forma normal los datos del giroscopio y del acelerómetro. En la librería \textit{imu.h} pueden consultarse los registros que se están leyendo.

\medskip Para la detección de caídas, se ha utilizado el eje Y del acelerómetro. El código programado se encuentra en el método \textit{getFall} de la librería \textit{raider.h}. Se sabe que en una posición vertical, el acelerómetro estará realizando una lectura de 1g provocada por la atracción gravitatoria terrestre. Al girar el robot en este eje, el valor medido irá disminuyendo. Cuando el robot se encuentro tumbado de forma perfectamente horizontal, el valor medido en el eje Y será de 0g. Dado que el incremento es proporcional se ha realizado una conversión sencilla en la que 1g corresponde con 0º de inclinación y 0g con 90º. Esta medida debe tomarse con el robot en reposo ya que de lo contrario el movimiento del robot influirá en su aceleración y podrá ser causa de falsos positivos. Se ha programado el sensor de forma que detecte caidas hacia delante cuando el robot se encuentre en una medición entre 90º y 60º, y caídas hacia atrás cuando mida entre 270º y 300º de inclinación. Este rango está parametrizado con la constante \textit{FALL\_DEGREES} que se encuentra en \textit{raider.h}

[ TODO image de caidas ]


\subsection{Brújula} 

Para la programación de la brújula se ha programado una biblioteca, \textit{compass.h} que controla de forma sencilla la extracción de datos. Atendiendo a su manual \cite{manualcmps03}, la CMPS03 ofrece tres formas de leer su medida:

\begin{itemize}
\item \textbf{Mediante PWM} 

El pin 4 del sensor permite realizar una lectura con 8 bits de precisión del valor medido por la brújula.

\item \textbf{Mediante I2C con 1 Byte}

Conectada por I2C, podemos realizar una lectura del registro 01 para obtener la medida de la brújula en un rango de 8 bits. 

\item \textbf{Mediante I2C con 2 Bytes}

Conectada por I2c, los registros 02 y 03 nos ofrecen una lectura de la medida de la brújula en un rango de 0 a 3600. De esta manera, la medida extraída tiene una precisión de $0.1º$ y no necesita ninguna adecuación.
\end{itemize}

Se eligió conectarla por I2C por la simplicidad en su cableado. Así mismo, se ha usado el método de lectura de dos registros por su mayor precisión. Con esto, será posible tomar una medida de la orientación del robot con solo realizar una consulta al sensor.


\section{Algoritmos de visión} 

Llegados a este punto, ya pueden programarse algoritmos de visión en el robot. A continuación se mostrarán tres algoritmos inspirados en la competición CEABOT.

\subsection{Análisis de trayectorias en navegación} 

El primer algoritmo que se ha programado es la búsqueda de trayectorias para la prueba de navegación. Este código puede consultarse en el método \textit{findWay()} de \textit{raider.h}.

\medskip El primer paso será tomar una foto del campo como la que aparece en la figura \ref{findway1}. Como se puede observar existe bastante suciedad en el suelo, hay marcas entre las tablas y algunos de los obstáculos provocan sombras.

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{figuras/findway1}   %raiderrangos
\caption{findway}
\label{findway1}
\end{figure}
\FloatBarrier

\medskip Tomando esta imagen como punto de partida, lo primero que se ha hecho es analizar cual es la superficie navegable. El código de este procedimiento se encuentra en la funcion \textit{detectGreen()} de \textit{eye.h}. En el sistema RGB cada pixel de una imagen describe su color en base a tres componentes: rojo, verde y azul. El objetivo será separar la imagen de tres canales en tres imagenes de un solo canal. En la imágen de la figura \ref{findway2} se muestran las tres imágenes fruto de la descomposición de la imagen original (De izquierda a derecha: Canal rojo, canal verde y canal azul).

\begin{figure}[h]
\centering
\begin{tabular}{ >{\centering\arraybackslash}m{0.33\textwidth} >{\arraybackslash}m{0.33\textwidth}  >{\arraybackslash}m{0.33\textwidth}}
\includegraphics[width=0.3\textwidth]{figuras/findway2r} & 
\includegraphics[width=0.3\textwidth]{figuras/findway2g} & 
\includegraphics[width=0.3\textwidth]{figuras/findway2b}\\
\end{tabular}\caption{Descomposición de la imagen en sus tres canales RGB}
\label{findway2}
\end{figure}
\FloatBarrier

\medskip La primera conclusión que puede sacarse al ver estas tres imágenes es que en el canal verde apenas existe contraste entre el color verde del suelo y el color blanco de los obstáculos. Esto tiene sentido ya que atendiendo a la teoría, un color verde puro (en RGB (0,255,0)) y un color blanco puro (en RGB (255,255,255)) contienen la misma cantidad de verde (255). En las otras dos imágenes, sí que se observa un mayor contraste. Si el color verde fuese puro, su componente azul y su componente roja serían nulas. Sin embargo, como se trabaja en un entorno real, los canales azul y rojo no muestran un color totalmente negro en el suelo.

\medskip El campo del campeonato CEABOT por normativa es de color verde, sin embargo no se especifica si la superficie será mate o brillante, si la iluminación estará bien enfocada... etc. Por ello, aunque a priori en el campo de pruebas de la Asociación de Robótica parezca que el canal que mejor diferencia el suelo y los obstáculos sea el canal rojo, en otros campos podremos encontrarnos que funciona mejor el canal azul.

\medskip Para solucionar esto, se ha realizado una mezcla de canales que aúne las características que nos conviene conservar de la muestra. La operación que se realiza es la siguiente. Por una parte, tomando como base la imágen del canal verde, le restaremos la imágen del canal rojo. Esto eliminará la componente de rojo residual que tiene la imagen del canal verde. Paralelamente, realizaremos la misma operación tomando como base la imágen del canal verde y restándole la imagen del canal azul para eliminar el azul residual. Las dos imágenes producto de ambas restas se muestran en la figura \ref{findway3} 

\begin{figure}[h]
\centering
\begin{tabular}{ >{\centering\arraybackslash}m{0.5\textwidth} >{\arraybackslash}m{0.5\textwidth}}
\includegraphics[width=0.45\textwidth]{figuras/findway3r} & 
\includegraphics[width=0.45\textwidth]{figuras/findway3b}\\
\end{tabular}\caption{Resta de canales verde y rojo, y de canales verde y azul}
\label{findway3}
\end{figure}
\FloatBarrier

\medskip Con esto, se han obtenido dos imágenes que conservan el color verde y carecen del resto. Para terminar, ambas imágenes se suman y el resultado obtenido, mostrado en la figura \ref{findway4}, supone la máxima detección de superficie navegable de la imagen original.

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{figuras/findway4}   
\caption{Detección de superficie navegable}
\label{findway4}
\end{figure}
\FloatBarrier

\medskip Ahora, la imagen podrá umbralizarse con bastante seguridad, ya que existe bastante diferencia entre la zona blanca y la negra. En la imagen \ref{findway5} se muestra cómo queda la imagen \ref{findway4} tras aplicarle un desenfoque para suavizar la textura y una umbralización. Esta imagen supone la salida de la función \textit{detectGreen()}.

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{figuras/findway5}   
\caption{Umbralización de obstáculos y superficie navegable}
\label{findway5}
\end{figure}
\FloatBarrier

\medskip Llegado este punto, ya se ha obtenido la información de qué elementos de la imagen constituyen obstáculos (zonas negras) y qué elemento constituye el suelo (zona blanca). A priori, se sabe que el robot podrá desplazarse con seguridad por la zona blanca, no obstante, será necesario indicar un camino que el robot pueda seguir. Para definir una trayectoria que recorra la superficie blanca, se ha optado por esqueletizar el contorno blanco. Existen muchos algoritmos de esqueletización, como el Hall \cite{hall1989fast}, el Guo-Hall \citep{guo1989parallel} o el Zhang-Suen \citep{zhang1984fast}. Se ha utilizado el algoritmo de Zhang-Suen porque es mas rápido que el resto y generalmente ofrece mejores resultados. Si aplicamos el algoritmo diretamente sobre la imagen \ref{findway5}, obtendremos la imagen mostrada en la figura \ref{findway6}. Junto a la imagen esqueletizada, se muestra un esquema de la proyección de la trayectoria sobre el campo.

\begin{figure}[h]
\centering
\begin{tabular}{ >{\centering\arraybackslash}m{0.5\textwidth} >{\arraybackslash}m{0.5\textwidth}}
\includegraphics[width=0.45\textwidth]{figuras/findway6} & 
\includegraphics[width=0.45\textwidth]{figuras/findway6m}\\
\end{tabular}\caption{Esqueletización del controno abierto y esquema del entorno}
\label{findway6}
\end{figure}
\FloatBarrier

\medskip La esqueletización funciona bastante bien, pero hay un problema. Dado que el contorno a esqueletizar toca los bordes de la imagen, su contorno no está totalmente definido. Para evitar esto se ha relizado una pequeña tranformación a la imágen antes de aplicarle el algoritmo. Esta transformación consiste en dibujar los bordes laterales de la imagen, de forma que corten el contorno y cierren su perímetro exterior. Una vez hecho esto, el resultado mejora notablemente, tal y como puede observarse en la figura \ref{findway7}

\begin{figure}[h]
\centering
\begin{tabular}{ >{\centering\arraybackslash}m{0.5\textwidth} >{\arraybackslash}m{0.5\textwidth}}
\includegraphics[width=0.45\textwidth]{figuras/findway7} & 
\includegraphics[width=0.45\textwidth]{figuras/findway7m}\\
\end{tabular}\caption{Esqueletización del contorno cerrado y esquema del entorno}
\label{findway7}
\end{figure}
\FloatBarrier

Para evaluar la acción que deberá tomar el robot, en cada muestra se toma un segmento cuyo punto de inicio coincide con el punto de inicio de la trayectoria, y cuyo punto final estará contenido en la trayectoria, a una distancia parametrizable. Este segmento puede observarse en la figura \ref{findway8}

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{figuras/findway8}   
\caption{Segmento de referencia para la extracción de datos (en azul)}
\label{findway8}
\end{figure}
\FloatBarrier

\medskip A partir de este segmento se han extraído dos datos. El primer dato, es la distancia horizontal que hay entre el robot y el inicio del segmento. El segundo dato es la orientación del segmento.

\medskip En la imagen de la figura \ref{findway9} se observa una situación en la que existen dos posibles caminos.

\begin{figure}[h]
\centering
\begin{tabular}{ >{\centering\arraybackslash}m{0.5\textwidth} >{\arraybackslash}m{0.5\textwidth}}
\includegraphics[width=0.45\textwidth]{figuras/findway9o} & 
\includegraphics[width=0.45\textwidth]{figuras/findway9} \\
\end{tabular}\caption{Esqueletización del contorno cerrado y esquema del entorno}
\label{findway9}
\end{figure}
\FloatBarrier

\medskip Cuando esto ocurre se hace una comprobación de cual de ellos es el que permite llegar mas lejos. En caso de que ambos caminos sean igual de largos, se escogerá el que esté mas cerca del robot. Ocurrirá de igual modo cuando el camino muestre una ramificación, se tomará la que permita llegar mas lejos. Esta situación puede observarse en la figura \ref{findway10}.

\begin{figure}[h]
\centering
\begin{tabular}{ >{\centering\arraybackslash}m{0.5\textwidth} >{\arraybackslash}m{0.5\textwidth}}
\includegraphics[width=0.45\textwidth]{figuras/findway10o} & 
\includegraphics[width=0.45\textwidth]{figuras/findway10} \\
\end{tabular}\caption{Esqueletización del contorno cerrado y esquema del entorno}
\label{findway10}
\end{figure}
\FloatBarrier

\subsection{Detección de lineas}

Otra de los algoritmos que se han desarrollado es la detección de lineas. En el campo de pruebas existen dos lineas blancas. Estas lineas marcan zonas del campo relevantes durante el desarrollo de la prueba, por tanto será necesario contar con un programa que detecte las lineas y su posición respecto al robot. El código puede consultarse en el método \textit{findLine} de \textit{raider.h}

Para comenzar, se tomará una imagen y se pasará por la función \textit{detectGreen}, detallada en el apartado anterior. A parte, para ahorrar recursos y aligerar el procesamiento, se recortará la imagen en altura. En la figura \ref{findline1} se muestra la imagen original junto a la que se tomará como punto de partida.

\begin{figure}[h]
\centering
\begin{tabular}{ >{\centering\arraybackslash}m{0.5\textwidth} >{\arraybackslash}m{0.5\textwidth}}
\includegraphics[width=0.45\textwidth]{figuras/findline1} & 
\includegraphics[width=0.45\textwidth]{figuras/findline2} \\
\end{tabular}
\caption{Imágen original e imágen tras aplicar la función \textit{detectGreen}}
\label{findline1}
\end{figure}
\FloatBarrier

\medskip Primero pasaremos a realizar una busqueda de contornos \cite{canny1986computational}, aplicando la función \textit{Canny()} de OpenCV. La imagen se transforma en la figura \ref{findline3}. Como puede verse en la imágen, se han marcado los filos de los contornos de la línea y del obstáculo.

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{figuras/findline3} \\
\caption{Detección de contornos}
\label{findline3}
\end{figure}
\FloatBarrier

\medskip Para que el algoritmo funcione correctamente, interesará que detecte la línea y el resto de cuerpos del campo no produzcan falsos positivos. Por tanto, el próximo objetivo es eliminar las rectas producidas por cuerpos stenos a la linea blanca. Una forma sencilla de lograr esto es el método de la dilatación y la erosión. Primero se dilatarán los contornos blancos de la imágen $n$ veces hasta que los dos filos de la linea blanca se unan, es decir, los dos contornos se convertirán en un contorno mas grueso. Tras ello, la imagen se erosionará $n+1$ veces. Esta erosión eliminará por completo las lineas producidas por cuerpos externos, pero mantendrá el contorno de la linea por ser mas grueso. Tras ello, el resultado es el que puede visualizarse en la figura \ref{findline4}

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{figuras/findline4} \\
\caption{Dilatación y erosión de contornos}
\label{findline4}
\end{figure}
\FloatBarrier

\medskip Ahora, una simple detección de líneas basada en la transformada de Hough \cite{hough}, será suficiente para definir la linea blanca. Para ello se ha utilizado la función de OpenCV, \textit{HoughLines}, ajustando empíricamente sus parámetros para definir una linea de una longitud adecuada y evitar falsos positivos de los restos de cuerpos externos que puedan quedar en la imágen. Tras realizar una búsqueda y proyectarla en la imágen original, se ha obtenido el resultado de la figura \ref{findline5}

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{figuras/findline5} \\
\caption{Resultado final de \textit{findLine}}
\label{findline5}
\end{figure}
\FloatBarrier

\subsection{Lectura de códigos QR} 
 
Para terminar, se ha realizado un algoritmo de detección de códigos QR basado en la librería ZBar \cite{brown2012zbar}. El algoritmo se utilizará tanto para la la prueba de visión del CEABOT como para dar instrucciones de propótito general al robot. Una de estas instrucciones podrá ser el inicio de una prueba, la selección de qué prueba debe realizar o cualquier otra que sea necesaria. El código programado se encuentra en la función \textit{findQR} de \textit{raider.h}

\medskip La librería ZBar está preparada para detectar diferentes tipos de códigos. En este caso, se ha limitado a que analice códigos QR en una imágen. A parte del código, podemos analizar su posición y su tamaño. En la figura \ref{findqr1} puede observar la detección de un marcador de la prueba de visión.	

\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{figuras/findqr} \\
\caption{Análisis de códigos QR en una imagen}
\label{findqr1}
\end{figure}
\FloatBarrier

\medskip Adicionalmente, se ha programado de que en el hipotético caso de que detecte dos códigos en una imágen, sólo analice el código que se encuentre más cerca del centro de la imágen. Gracias a esto, el sistema será mas robusto de cara a la prueba de visión del CEABOT.